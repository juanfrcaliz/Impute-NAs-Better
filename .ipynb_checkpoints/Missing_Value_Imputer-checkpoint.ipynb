{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.en\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df,n_models=None, var_deviation_tolerance=0.97, actual_or_gaussian_residuals='actual', col_floor_ceiling_dict=None):\n",
    "    columns = df.columns\n",
    "    missing_columns = list(df.isna().sum()[df.isna().sum()>0].sort_values().index)\n",
    "    have_columns = [i for i in columns if i not in missing_columns]\n",
    "    for col in tqdm.tqdm(missing_columns):\n",
    "        percent_missing = df[col].isna().sum()/df.shape[0]\n",
    "        m = math.ceil(percent_missing/((1/.97)-1))\n",
    "        print(col,percent_missing,m)\n",
    "        other_columns = [i for i in columns if i != col]\n",
    "        na_index = df[df[col].isna()==1].index\n",
    "        have_index = [i for i in df.index if i not in na_index]\n",
    "        na_have_cols = set(df.loc[na_index,other_columns].dropna(axis=1).columns)\n",
    "        have_have_cols = set(df.loc[have_index,other_columns].dropna(axis=1).columns)\n",
    "        both_cols = na_have_cols.intersection(have_have_cols)\n",
    "        int_df = pd.get_dummies(df.loc[:,both_cols],drop_first=True)\n",
    "        X_have = int_df.loc[have_index,:]\n",
    "        y_have = df[col][have_index]\n",
    "        X_na = int_df.loc[na_index,:]\n",
    "        if type_dict[col]=='object':\n",
    "            le = LabelEncoder()\n",
    "            y_have = le.fit_transform(y_have)\n",
    "            df[col][have_index] = y_have\n",
    "            rf = RandomForestClassifier()\n",
    "            bagc = BaggingClassifier(base_estimator=rf,n_estimators=m)\n",
    "            bagc.fit(X_have,y_have)\n",
    "            print(bagc.score(X_have,y_have))\n",
    "            resid_preds = bagc.predict(X_have)\n",
    "            residuals = y_have-resid_preds\n",
    "            preds = bagc.predict(X_na)\n",
    "        else:\n",
    "            bagr = BaggingRegressor(n_estimators=m)\n",
    "            bagr.fit(X_have,y_have)\n",
    "            print(bagr.score(X_have,y_have))\n",
    "            resid_preds = bagr.predict(X_have)\n",
    "            residuals = y_have-resid_preds\n",
    "            preds = bagr.predict(X_na)\n",
    "        if actual_or_gaussian_residuals=='actual':\n",
    "            rand_resids = residuals.sample(n=len(nas_x),replace=True)\n",
    "        else:\n",
    "            rand_resids = np.random.normal(residuals.mean(),residuals.std(),len(nas_x))\n",
    "        preds = preds + rand_resids\n",
    "        if type_dict[col]=='object':\n",
    "            preds = preds.round()\n",
    "        if col in col_floor_ceiling_dict.keys():\n",
    "                impute_preds = impute_preds.apply(lambda x: min(col_floor_ceiling_dict[col][1],x))\n",
    "                impute_preds = impute_preds.apply(lambda x: max(col_floor_ceiling_dict[col][0],x))\n",
    "        df[col][na_index] = preds\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(df,n_models=None, var_deviation_tolerance=0.97, actual_or_gaussian_residuals='actual', col_floor_ceiling_dict=None):\n",
    "    #Calculate the number of models to bag\n",
    "    percent_missing = df.isna().sum().sum()/len(df)\n",
    "    if n_models==None:\n",
    "        n_models = math.ceil(percent_missing/((1/var_deviation_tolerance)-1))\n",
    "    imputed_df = copy.copy(df)\n",
    "    bagr = BaggingRegressor(n_estimators=n_models,bootstrap_features=True)\n",
    "    bagc = BaggingClassifier(n_estimators=n_models,bootstrap_features=True)\n",
    "    columns = df.columns\n",
    "    na_cols = list(df.isna().sum()[df.isna().sum()>0].index)\n",
    "    type_dict = dict(zip(columns,[i.name for i in df.dtypes]))\n",
    "    for col in na_cols:\n",
    "        #get rows for col nas\n",
    "        nas_index = df[col][df[col].isna()==1].index.to_list()\n",
    "        have_index = [i for i in df[col].index if i not in nas_index]\n",
    "        #get columns with no nas other than the one currently being imputed \n",
    "        nas_x = pd.get_dummies(df.iloc[nas_index,:].dropna(axis=1),drop_first=True)\n",
    "        have_no_nas = df.loc[have_index,dont_have_no_nas.columns].dropna()\n",
    "        # dont_have_no_nas = df.iloc[nas_index,:].drop(col,axis=1).dropna()\n",
    "        X_df = pd.get_dummies(have_no_nas,drop_first=True)\n",
    "        y = df.loc[have_index,col]\n",
    "        if type_dict[col]=='object':\n",
    "            y_values = y.unique().tolist()\n",
    "            y_all = pd.get_dummies(y)\n",
    "            y = pd.get_dummies(y,drop_first=True)\n",
    "            bagc.fit(X_df,y)\n",
    "            train_preds = bagc.predict(X_df)\n",
    "        else:\n",
    "            bagr.fit(X_df,y)\n",
    "            train_preds = bagr.predict(X_df)\n",
    "        if type_dict[col]=='object':\n",
    "            new_preds = np.zeros((train_preds.shape[0],train_preds.shape[1]+1))\n",
    "            for i in range(len(train_preds)):\n",
    "                one_value = 1-train_preds[i].sum()\n",
    "                new_preds[i] = np.insert(train_preds[i],0,one_value,axis=0)\n",
    "            residuals = y_all- new_preds\n",
    "            if actual_or_gaussian_residuals=='actual':\n",
    "                rand_resids = residuals.sample(n=len(nas_x),replace=True)\n",
    "            else:\n",
    "                rand_resids = np.random.normal(residuals.mean(),residuals.std(),len(nas_x))\n",
    "            impute_preds = bagr.predict(nas_x)\n",
    "            new_impute_preds = np.zeros((impute_preds.shape[0],impute_preds.shape[1]+1))\n",
    "            for i in range(len(impute_preds)):\n",
    "                one_value = 1-impute_preds[i].sum()\n",
    "                new_impute_preds[i] = np.insert(impute_preds[i],0,one_value,axis=0)\n",
    "            new_impute_preds = new_impute_preds + rand_resids\n",
    "            impute_preds = np.zeros(len(new_impute_preds),dtype='object')\n",
    "            for i in range(new_impute_preds.shape[0]):\n",
    "                impute_preds[i]=np.argmax(new_impute_preds.iloc[i,:])\n",
    "        else:\n",
    "            residuals = (y-train_preds)\n",
    "            impute_preds = bagr.predict(nas_x)\n",
    "            if actual_or_gaussian_residuals=='actual':\n",
    "                rand_resids = residuals.sample(n=len(nas_x),replace=True)\n",
    "            else:\n",
    "                rand_resids = np.random.normal(residuals.mean(),residuals.std(),len(nas_x))\n",
    "            impute_preds = impute_preds + rand_resids\n",
    "            if col in col_floor_ceiling_dict.keys():\n",
    "                impute_preds = impute_preds.apply(lambda x: min(col_floor_ceiling_dict[col][1],x))\n",
    "                impute_preds = impute_preds.apply(lambda x: max(col_floor_ceiling_dict[col][0],x))\n",
    "        imputed_df[col][nas_index] = impute_preds\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_dict = {'play_star_ratings': (0,5),'star_rating': (0,5),'val_star_rating':(0,5),'num_reviews':(0,float('inf'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical values into strings\n",
    "# Identify missing values\n",
    "\n",
    "def impute(df):\n",
    "    imputed_df = pd.DataFrame(None,index=df.index)\n",
    "    percent_missing = df.isna().sum().sum()/len(df)\n",
    "    m = math.ceil(percent_missing/((1/.97)-1))\n",
    "    bagc = BaggingClassifier(base_estimator = LogisticRegression, n_estimators=m)\n",
    "    bagr = BaggingRegressor(n_estimators=m)\n",
    "    columns = df.columns\n",
    "    type_dict = dict(zip(columns,[i.name for i in df.dtypes]))\n",
    "    for col in columns:\n",
    "        na_index = df[df[col].isna().any(axis=1)==1].index\n",
    "        have_index = [i for i in df.index if i not in na_index]\n",
    "        have = df[col][df[col].isna().any(axis=1)==0]\n",
    "        other_columns = [i for i in columns if i != col]\n",
    "        #this needs fixing\n",
    "        other_df = df.loc[:,[col,other_columns]]\n",
    "        other_no_na_columns = (other_df.isna().sum())[other_df.isna().sum()==0]\n",
    "        other_no_nas_df = other_df.loc[:,[col,other_no_na_columns]]\n",
    "        other_no_nas_df = pd.get_dummies(other_no_nas_df.dropna(),drop_first=True)\n",
    "        #deal with dummy variables\n",
    "        if type_dict[col]=='object':\n",
    "            bagc.fit(other_no_nas_df.iloc[:,1:],other_no_nas_df[col])\n",
    "            resid_preds = bagc.predict(other_no_nas_df.iloc[:,1:])\n",
    "            residuals = other_no_nas_df[col]-resid_preds\n",
    "            bagc.predict(other_no_nas_df.iloc[:,1:],other_no_nas_df[col])\n",
    "            preds = bagc.predict(others_no_nas_df[others_no_nas_df[col].isna()==True])\n",
    "        else:\n",
    "            bagr.fit(other_no_nas_df.iloc[:,1:],other_no_nas_df[col])\n",
    "            resid_preds = bagr.predict(other_no_nas_df.iloc[:,1:])\n",
    "            residuals = other_no_nas_df[col]-resid_preds\n",
    "            bagr.fit(other_no_nas_df.iloc[:,1:],other_no_nas_df[col].dropna())\n",
    "            preds = bagr.predict(others_no_nas_df[others_no_nas_df[col].isna()==True])\n",
    "        preds = preds + np.random.normal(residuals.mean(),residuals.std(),len(preds))\n",
    "        all_values = have.append(pd.DataFrame(preds,columns=[col],index=na_index)).sort_index()\n",
    "        df[col] = all_values\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
